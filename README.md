# HousePricePrediction
A house price prediction system according to the size of the house is made using Linear Regression, for the completion of my second assignment under the academic  ml course.

Project Overview:

This project demonstrates how Linear Regression works:

Implemented from scratch using Gradient Descent.

Compared with Scikit-learnâ€™s LinearRegression for validation.

The goal is to understand what happens behind the scenes in Linear Regression and verify correctness by comparing with the scikit-learn implementation.

âš™ï¸ How Things Work
1. Dataset

We generate synthetic data using make_regression from scikit-learn.

The dataset has input features X and a target variable y.

ğŸ‘‰ Think of it as predicting output y given some input X.

2. Linear Regression from Scratch

We build a custom Linear Regression model using Gradient Descent.

Steps:

Initialize Parameters: Start with random weights and bias.

Prediction: Compute

ğ‘¦
^
=
ğ‘‹
ğ‘Š
+
ğ‘
y
^
	â€‹

=XW+b

where 
ğ‘Š
W = weights, 
ğ‘
b = bias.

Loss Function: Use Mean Squared Error (MSE) to measure error between predicted and actual values.

ğ‘€
ğ‘†
ğ¸
=
1
ğ‘›
âˆ‘
(
ğ‘¦
âˆ’
ğ‘¦
^
)
2
MSE=
n
1
	â€‹

âˆ‘(yâˆ’
y
^
	â€‹

)
2

Gradient Descent Update: Adjust weights & bias to minimize error.

ğ‘Š
:
=
ğ‘Š
âˆ’
ğ›¼
â‹…
âˆ‚
ğ‘€
ğ‘†
ğ¸
âˆ‚
ğ‘Š
,
ğ‘
:
=
ğ‘
âˆ’
ğ›¼
â‹…
âˆ‚
ğ‘€
ğ‘†
ğ¸
âˆ‚
ğ‘
W:=Wâˆ’Î±â‹…
âˆ‚W
âˆ‚MSE
	â€‹

,b:=bâˆ’Î±â‹…
âˆ‚b
âˆ‚MSE
	â€‹


where 
ğ›¼
Î± = learning rate.

Repeat for many epochs until the loss reduces.

3. Training Visualization

We plot Epoch vs Loss to see how the model improves over time.

Loss decreases gradually â†’ shows Gradient Descent is working.

4. Scikit-learn Linear Regression

We fit LinearRegression() on the same dataset.

This uses the Normal Equation (analytical solution) instead of Gradient Descent.

Formula used:

ğ‘Š
=
(
ğ‘‹
ğ‘‡
ğ‘‹
)
âˆ’
1
ğ‘‹
ğ‘‡
ğ‘¦
W=(X
T
X)
âˆ’1
X
T
y
5. Comparison of Results

Print learned weights and bias from both models.

If the scratch model works correctly, its parameters should be very close to scikit-learnâ€™s.

ğŸ“Š Output Example

Loss Curve: Shows convergence of Gradient Descent.

Weights & Bias: Nearly same values from both scratch & scikit-learn models.

ğŸš€ Key Learning Outcomes

Understand how Linear Regression actually works (not just using libraries).

Learn how Gradient Descent optimizes parameters.

Verify correctness by comparing with scikit-learnâ€™s solution.

ğŸ› ï¸ Requirements

Python 3.x

NumPy

Matplotlib

scikit-learn

Install via:

pip install numpy matplotlib scikit-learn

â–¶ï¸ How to Run
python linear_regression_scratch.py
